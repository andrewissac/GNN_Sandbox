{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import copy\n",
    "import glob\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from trainAndEval import train, evaluate\n",
    "from dgl.data import DGLDataset\n",
    "from TrainResults import TrainResults\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from DGL_GCN import Deep_DGL_GCN\n",
    "from ToyDGLDataset_v2 import ToyDGLDataset_v2, GetNodeFeatureVectors, GetEdgeFeatureVectors, GetNeighborNodes, GetEdgeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def trainEpochs(model, device, dataloader, optimizer, loss_fn, batchsize, nEpochs):\n",
    "    results = TrainResults()\n",
    "    results.startTrainingTimer()\n",
    "    bestModel = None\n",
    "    bestValAcc = 0.0\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        # train\n",
    "        epochLoss = train(model, device, dataloader, optimizer, loss_fn, batchsize, results)\n",
    "\n",
    "        # evaluate\n",
    "        train_result = evaluate(model, device, train_dataloader, loss_fn)\n",
    "        val_result = evaluate(model, device, val_dataloader, loss_fn)\n",
    "        test_result = evaluate(model, device, test_dataloader, loss_fn)\n",
    "\n",
    "        results.addEpochResult(epochLoss, train_result, val_result, test_result)\n",
    "\n",
    "        #if(epoch % 5 == 0):\n",
    "        #    results.printLastResult()\n",
    "\n",
    "        if results.best_val_acc > bestValAcc:\n",
    "            bestValAcc = results.best_val_acc\n",
    "            bestModel = copy.deepcopy(model)\n",
    "            \n",
    "    results.endTrainingTimer()\n",
    "\n",
    "    return results, bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllDatasetNames(datasetRootDir):\n",
    "    files = glob.glob(datasetRootDir + '/*/*/*.json', recursive=True)\n",
    "    #files = [x for x in files if \"Toy2_v3_0\" in x]\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "\n",
    "datasetRootDir = '/home/andrew/GNN_Sandbox/GraphToyDatasets_v3'\n",
    "datasetDirs, datasetNames = getAllDatasetNames(datasetRootDir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datasetName = datasetNames[0]\n",
    "datasetDir = datasetDirs[0]\n",
    "dataset = ToyDGLDataset_v2(datasetName, datasetDir)\n",
    "dataset.printProperties()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'Label: {label}')\n",
    "print(GetNodeFeatureVectors(graph))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batched_graph, labels = batch\n",
    "print('Number of nodes for each graph element in the batch:', batched_graph.batch_num_nodes())\n",
    "print('Number of edges for each graph element in the batch:', batched_graph.batch_num_edges())\n",
    "print(labels)\n",
    "# Recover the original graph elements from the minibatch\n",
    "graphs = dgl.unbatch(batched_graph)\n",
    "print('The original graphs in the minibatch:')\n",
    "print(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "##############################################################\n",
      "----------------LAYER COUNT: 2-------------------\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_0NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 14, Loss: 0.6951, Validation Loss: 0.6932, Train: 0.498, Validation: 0.504, Test: 0.492, AUC: 0.493\n",
      "\n",
      "The training took 243 seconds (4.05 minutes).\n",
      "------------------(1/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_11NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 1.0954, Validation Loss: 0.5822, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.740\n",
      "\n",
      "The training took 237 seconds (3.95 minutes).\n",
      "------------------(2/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_1NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.8353, Validation Loss: 0.6932, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.500\n",
      "\n",
      "The training took 251 seconds (4.18 minutes).\n",
      "------------------(3/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_2NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 27, Loss: 0.6911, Validation Loss: 0.6921, Train: 0.537, Validation: 0.541, Test: 0.543, AUC: 0.552\n",
      "\n",
      "The training took 249 seconds (4.15 minutes).\n",
      "------------------(4/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_3NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.6992, Validation Loss: 0.6932, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.500\n",
      "\n",
      "The training took 253 seconds (4.22 minutes).\n",
      "------------------(5/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_4NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.6932, Validation Loss: 0.6932, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.500\n",
      "\n",
      "The training took 253 seconds (4.22 minutes).\n",
      "------------------(6/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_5NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.7012, Validation Loss: 0.6932, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.500\n",
      "\n",
      "The training took 257 seconds (4.28 minutes).\n",
      "------------------(7/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_7NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.6932, Validation Loss: 0.6932, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.500\n",
      "\n",
      "The training took 247 seconds (4.12 minutes).\n",
      "------------------(8/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy0_v3_1_9NodeCountMeanDiff\n",
      "Best epoch: \n",
      "Epoch: 0, Loss: 0.6502, Validation Loss: 0.6090, Train: 0.498, Validation: 0.502, Test: 0.506, AUC: 0.721\n",
      "\n",
      "The training took 257 seconds (4.28 minutes).\n",
      "------------------(9/27) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Toy2_v3_0_0percentDiff\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4c111ca15100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Beginning training on dataset {datasetNames[i]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainEpochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintBestResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-12988c3efd08>\u001b[0m in \u001b[0;36mtrainEpochs\u001b[0;34m(model, device, dataloader, optimizer, loss_fn, batchsize, nEpochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mepochLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GNN_Sandbox/trainAndEval.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloader, optimizer, loss_fn, batchsize, results)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbatchIter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mbatched_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mbatched_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(graphs, ndata, edata, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mbnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mntype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0mretg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_batch_num_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/GNNSandbox/venv/lib/python3.8/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mbnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mntype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0mretg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_batch_num_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "\n",
    "batchSize = 1024\n",
    "print(f'Device: {device}')\n",
    "\n",
    "for nLayer in range(2,11):\n",
    "    print(f'##############################################################')\n",
    "    print(f'----------------LAYER COUNT: {nLayer}-------------------')\n",
    "    for i in range(len(datasetDirs)):\n",
    "        dataset = ToyDGLDataset_v2(datasetNames[i], datasetDirs[i])\n",
    "        splitIndices = dataset.get_split_indices()\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(splitIndices['train'])\n",
    "        val_sampler = SubsetRandomSampler(splitIndices['valid'])\n",
    "        test_sampler = SubsetRandomSampler(splitIndices['test'])\n",
    "\n",
    "        train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=batchSize, drop_last=False)\n",
    "        val_dataloader = GraphDataLoader(dataset, sampler=val_sampler, batch_size=batchSize, drop_last=False)\n",
    "        test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=batchSize, drop_last=False)\n",
    "\n",
    "        # Create the model with given dimensions\n",
    "        model = Deep_DGL_GCN(dataset.dim_nfeats, 16, dataset.num_graph_classes, nLayer, 0).to(device)\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        epochs = 30\n",
    "\n",
    "        # train\n",
    "        print(f'Beginning training on dataset {datasetNames[i]}')\n",
    "        results, bestmodel = trainEpochs(model, device, train_dataloader, optimizer, loss_fn, batchSize, epochs)\n",
    "        results.printBestResult()\n",
    "\n",
    "        # save results\n",
    "        outputFolder = path.join(path.join(datasetDirs[i], \"ThesisPlots/Deepness\"), f'DGL_GCN_Layers_{nLayer}')\n",
    "        Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results.savePlots(outputFolder)\n",
    "        results.dumpSummary(outputFolder)\n",
    "        results.pickledump(outputFolder)\n",
    "\n",
    "        # save the best model for inference. (when loading for inference -> model.eval()!! )\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "        torch.save(bestmodel.state_dict(), path.join(outputFolder, 'model.pt'))\n",
    "\n",
    "        print(f'------------------({i+1}/{len(datasetDirs)}) models trained------------------\\n')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - now\n",
    "print(f'{elapsed} seconds elapsed')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = TrainResults.loadPickle('test.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(graph.nodes[[0,1]])\n",
    "print(graph.nodes[0])\n",
    "print(graph.nodes[1])\n",
    "print(graph.nodes[10])\n",
    "print(graph.nodes[3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print(graph.out_edges(7))\n",
    "#print(graph.edges[(0,1)]) # src, dst\n",
    "#print(graph.edges[0,1]) # src, dst\n",
    "print(graph.edges[[0, 0], [1,2]]) # src, dst\n",
    "print(graph.edges[[10], [3]])\n",
    "print(graph.edges[[3], [10]])\n",
    "print(graph.edges[0])\n",
    "print(graph.edges[1])\n",
    "#print(graph.edges[0]) # eid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "edgeList = GetNeighborNodes(graph, 0)\n",
    "nodeFeat = graph.ndata['feat']\n",
    "print(graph.nodes[0])\n",
    "print(nodeFeat)\n",
    "print(edgeList)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def ConcatNodeAndEdgeFeatures(graph, nodeFeat, nodeLabel: int):\n",
    "    neighbors = GetNeighborNodes(graph, nodeLabel)\n",
    "    nfeat = nodeFeat[nodeLabel]\n",
    "    efeat = torch.reshape(graph.edges[neighbors].data['feat'], (-1,))\n",
    "    #print(nfeat)\n",
    "    #print(efeat)\n",
    "    return torch.cat((nfeat, efeat))\n",
    "    \n",
    "x = ConcatNodeAndEdgeFeatures(graph, nodeFeat, 0)\n",
    "print(x)\n",
    "\n",
    "edgeFeatureVec = GetEdgeFeatureVectors(graph)\n",
    "\n",
    "x = (1,2,3)\n",
    "print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
